{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPmH_9UbUrE_"
      },
      "source": [
        "## Directory Managing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_path = '/content/updated_train_data500images_corrected.csv'\n",
        "val_csv_path = ''\n",
        "test_csv_path = ''\n",
        "\n",
        "\n",
        "lexicon_file_path = '/content/lexicon.txt'\n",
        "\n",
        "store_knn_classifier = '/content/knn_phoc_classifier1.pkl'"
      ],
      "metadata": {
        "id": "s1fUputfdhoz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg9i8hefOZYB",
        "outputId": "03671293-130b-45aa-ba7e-b5cec06ab3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.3.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "# Library loading\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "!pip install wandb\n",
        "import wandb\n",
        "import editdistance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "jxeO_ns2E1v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2196142b-38d2-42c2-9f29-b33709213cb4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wandb Functions"
      ],
      "metadata": {
        "id": "3FbgbuHPF6t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set of functions to log different aspects of our model's execution on wandb\n",
        "\n",
        "def train_log(loss, total_example_ct):\n",
        "    wandb.log({\"loss\": loss}, step=total_example_ct)\n",
        "    print(f\"Loss after {str(total_example_ct).zfill(5)} examples: {loss:.3f}\")\n",
        "\n",
        "def train_test_log(loss_test, loss_train, accuracy_test, accuracy_train, edit_test, edit_train, epoch):\n",
        "    wandb.log({\"Epoch\": epoch,\n",
        "               \"Train loss\": loss_train, \"Test loss\": loss_test,\n",
        "               \"Train accuracy\": accuracy_train, \"Test accuracy\": accuracy_test,\n",
        "               \"Train edit\": edit_train, \"Test edit\": edit_test,\n",
        "               })\n",
        "    print(f\"Train Loss: {loss_train:.3f}\\nTest Loss: {loss_test:.3f}\")\n",
        "\n",
        "\n",
        "# Set of functions to log the images into wandb\n",
        "def log_images(images, predicted_labels, text_labels, epoch, mode):\n",
        "    t = transforms.Compose([transforms.Normalize(0, 1/0.1),transforms.Normalize(-0.5, 1)])\n",
        "    t_images = t(images)\n",
        "    images_with_labels = draw_images(t_images, text_labels, predicted_labels)\n",
        "    wandb.log({f\"Epoch{epoch}-{mode}\": [wandb.Image(im) for im in images_with_labels]})\n",
        "\n",
        "def draw_images(images, text_labels, predicted_labels):\n",
        "    transform = T.ToPILImage()\n",
        "    images = [draw_one_image(transform(im), t_lab, p_lab) for im, t_lab, p_lab in zip(images, text_labels, predicted_labels)]\n",
        "    return images\n",
        "\n",
        "def draw_one_image(image, text_label, predicted_label):\n",
        "    image = image.convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    if text_label == predicted_label:\n",
        "        color = \"green\"\n",
        "    else:\n",
        "        color = \"red\"\n",
        "    text = text_label + \"\\n\" + predicted_label\n",
        "\n",
        "    # Use the default font\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    draw.text((0, 0), text, font=font, fill=color)\n",
        "    return image\n",
        "\n",
        "# Log the learning rate\n",
        "def lr_log(lr, epoch):\n",
        "    wandb.log({\"learning-rate\": lr}, step=epoch)"
      ],
      "metadata": {
        "id": "V416_D7ZF9XE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s8RtQjjU3nC"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i51aCp0MOZYD"
      },
      "outputs": [],
      "source": [
        "# Load the csv files: they contain image_path, label\n",
        "train_data = pd.read_csv(train_csv_path)\n",
        "test_data = pd.read_csv(test_csv_path)\n",
        "val_data = pd.read_csv(val_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rqlXaKsGOZYD"
      },
      "outputs": [],
      "source": [
        "list_of_words =  train_data['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND7R8hJPOZYD",
        "outputId": "7f93fefd-8733-482b-f43b-1e716781514e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Works\n"
          ]
        }
      ],
      "source": [
        "# Checking if labels have been loaded correctly\n",
        "if 'TREASONOUS' in list_of_words:\n",
        "    print(\"Works\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "1SIY1OSeOZYD",
        "outputId": "348901a5-e4aa-4cef-997e-453bf813595f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=149x31>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 149, 3)\n",
            "pegged\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=104x31>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 104, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# Checking the images and their dimentions\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "img = cv2.imread('/content/144_EMIGRANTS_25365.jpg')\n",
        "\n",
        "cv2_imshow(img)\n",
        "plt.imshow(img)\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "img = cv2.imread(train_data['image_path'][2])\n",
        "print(train_data['label'][2])\n",
        "\n",
        "cv2_imshow(img)\n",
        "plt.imshow(img)\n",
        "print(img.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHOC and KNN"
      ],
      "metadata": {
        "id": "9y2xZHY6dSev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_phoc(words, phoc_unigrams, unigram_levels,\n",
        "               bigram_levels=None, phoc_bigrams=None,\n",
        "               split_character=None):\n",
        "    '''\n",
        "    Calculate Pyramidal Histogram of Characters (PHOC) descriptor (see Almazan 2014).\n",
        "    Args:\n",
        "        word (str): word to calculate descriptor for\n",
        "        phoc_unigrams (str): string of all unigrams to use in the PHOC\n",
        "        unigram_levels (list of int): the levels for the unigrams in PHOC\n",
        "        phoc_bigrams (list of str): list of bigrams to be used in the PHOC\n",
        "        phoc_bigram_levls (list of int): the levels of the bigrams in the PHOC\n",
        "        split_character (str): special character to split the word strings into characters\n",
        "        on_unknown_unigram (str): What to do if a unigram appearing in a word\n",
        "            is not among the supplied phoc_unigrams. Possible: 'warn', 'error'\n",
        "    Returns:\n",
        "        the PHOC for the given word\n",
        "    '''\n",
        "    # prepare output matrix\n",
        "    phoc_size = len(phoc_unigrams) * np.sum(unigram_levels)\n",
        "    if phoc_bigrams is not None:\n",
        "        phoc_size += len(phoc_bigrams) * np.sum(bigram_levels)\n",
        "    phocs = np.zeros((len(words), phoc_size))\n",
        "\n",
        "    # prepare some lambda functions\n",
        "    occupancy = lambda k, n: [float(k) / n, float(k + 1) / n]\n",
        "    overlap = lambda a, b: [max(a[0], b[0]), min(a[1], b[1])]\n",
        "    size = lambda region: region[1] - region[0]\n",
        "\n",
        "    # map from character to alphabet position\n",
        "    char_indices = {d: i for i, d in enumerate(phoc_unigrams)}\n",
        "\n",
        "    # iterate through all the words\n",
        "    for word_index, word in enumerate(words):\n",
        "        \"\"\"if '0' in word or '1' in word or '2' in word or '3' in word or '4' in word or '5' in word or '6' in word or '7' in word or '7' in word or '8' in word or '9' in word:\n",
        "            continue\"\"\"\n",
        "        if split_character is not None:\n",
        "            word = word.split(split_character)\n",
        "        n = len(word)\n",
        "        for index, char in enumerate(word):\n",
        "            char_occ = occupancy(index, n)\n",
        "            char_index = char_indices[char]\n",
        "\n",
        "            for level in unigram_levels:\n",
        "                for region in range(level):\n",
        "                    region_occ = occupancy(region, level)\n",
        "                    if size(overlap(char_occ, region_occ)) / size(char_occ) >= 0.5:\n",
        "                        feat_vec_index = sum([l for l in unigram_levels if l < level]) * len(\n",
        "                            phoc_unigrams) + region * len(phoc_unigrams) + char_index\n",
        "                        phocs[word_index, feat_vec_index] = 1\n",
        "\n",
        "        # add bigrams\n",
        "        if phoc_bigrams is not None:\n",
        "            ngram_features = np.zeros(len(phoc_bigrams) * np.sum(bigram_levels))\n",
        "            ngram_occupancy = lambda k, n: [float(k) / n, float(k + 2) / n]\n",
        "\n",
        "            for i in range(n - 1):\n",
        "                ngram = word[i:i + 2]\n",
        "                phoc_dict = {k: v for v, k in enumerate(phoc_bigrams)}\n",
        "                if phoc_dict.get(ngram, 666) == 666:\n",
        "                    continue\n",
        "                occ = ngram_occupancy(i, n)\n",
        "\n",
        "                for level in bigram_levels:\n",
        "                    for region in range(level):\n",
        "                        region_occ = occupancy(region, level)\n",
        "                        overlap_size = size(overlap(occ, region_occ)) / size(occ)\n",
        "                        if overlap_size >= 0.5:\n",
        "                            ngram_features[region * len(phoc_bigrams) + phoc_dict[ngram]] = 1\n",
        "            phocs[word_index, -ngram_features.shape[0]:] = ngram_features\n",
        "\n",
        "    return phocs\n",
        "\n",
        "# Computes the phoc vector for a given str\n",
        "def phoc(raw_word):\n",
        "    if isinstance(raw_word, list):\n",
        "        word = [w.lower() for w in raw_word]\n",
        "    else:\n",
        "        word = [raw_word.lower()]\n",
        "    phoc_unigrams = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
        "    unigram_levels = [2, 3, 4, 5]\n",
        "    bigram_levels = [2]\n",
        "    phoc_bigrams = ['th', 'he', 'in', 'er', 'an',\n",
        "                    're', 'on', 'at', 'en', 'nd',\n",
        "                    'ti', 'es', 'or', 'te', 'of',\n",
        "                    'ed', 'is', 'it', 'al', 'ar',\n",
        "                    'st', 'to', 'nt', 'ng', 'se',\n",
        "                    'ha', 'as', 'ou', 'io', 'le',\n",
        "                    've', 'co', 'me', 'de', 'hi',\n",
        "                    'ri', 'ro', 'ic', 'ne', 'ea',\n",
        "                    'ra', 'ce', 'li', 'ch', 'll',\n",
        "                    'be', 'ma', 'si', 'om', 'ur']\n",
        "\n",
        "    qry_phocs = build_phoc(words=word, phoc_unigrams=phoc_unigrams, unigram_levels=unigram_levels,\n",
        "                           bigram_levels=bigram_levels, phoc_bigrams=phoc_bigrams)\n",
        "    return torch.tensor(qry_phocs[0])"
      ],
      "metadata": {
        "id": "GF48qbW9b4HD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read words from the .txt file\n",
        "with open('/content/lexicon.txt', 'r') as file:\n",
        "    words = [line.strip() for line in file]\n",
        "\n",
        "# Compute PHOC descriptors\n",
        "phoc_descriptors = []\n",
        "for word in words:\n",
        "    phoc_descriptors.append(phoc(word).numpy())\n",
        "\n",
        "phoc_descriptors = np.array(phoc_descriptors)\n",
        "\n",
        "# Initialize and train the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(phoc_descriptors, words)\n",
        "\n",
        "# Save the trained KNN classifier to a file\n",
        "with open('knn_phoc_classifier1.pkl', 'wb') as knnPickle:\n",
        "    pickle.dump(knn, knnPickle)\n",
        "\n",
        "print(\"KNN classifier trained and saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH6ocO51eRa-",
        "outputId": "64f9cc68-4615-47a1-ebac-987574e61cbb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN classifier trained and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking that the shape is 604\n",
        "print(phoc_descriptors[6788].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5LZ7Hlgf25Z",
        "outputId": "ba814ca5-12fa-4dc8-8a8f-638ce895298b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(604,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "zXzahATGmlhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Custom Dataset on which to load the image & its labels (both in str and phoc vector form)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file_path, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file_path)\n",
        "        self.transform = transform\n",
        "        self.label_to_index = {label: idx for idx, label in enumerate(self.data_frame['label'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data_frame.iloc[idx, 0]\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        str_label = self.data_frame.iloc[idx, 1].lower()\n",
        "        target = phoc(str_label)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target, str_label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "qsMb1hs8mjrw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "h4Uj9636GnaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SPP(nn.Module):\n",
        "    def __init__(self, levels=3, pool_type='max_pool'):\n",
        "        super(SPP, self).__init__()\n",
        "\n",
        "        # Check if the pool_type is valid\n",
        "        if pool_type not in ['max_pool', 'avg_pool', 'max_avg_pool']:\n",
        "            raise ValueError('Unknown pool_type. Must be either \\'max_pool\\', \\'avg_pool\\' or both')\n",
        "\n",
        "        self.pooling_output_size = sum([4 ** level for level in range(levels)]) * 512\n",
        "        self.levels = levels\n",
        "        self.pool_type = pool_type\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        out = self._spatial_pyramid_pooling(input_x, self.levels)\n",
        "        return out\n",
        "\n",
        "    def _pyramid_pooling(self, input_x, output_sizes):\n",
        "        pyramid_level_tensors = []\n",
        "\n",
        "        # Support for various types of pooling\n",
        "        for tsize in output_sizes:\n",
        "            if self.pool_type == 'max_pool':\n",
        "                pyramid_level_tensor = F.adaptive_max_pool2d(input_x, tsize)\n",
        "                pyramid_level_tensor = pyramid_level_tensor.view(input_x.size(0), -1)\n",
        "            if self.pool_type == 'avg_pool':\n",
        "                pyramid_level_tensor = F.adaptive_avg_pool2d(input_x, tsize)\n",
        "                pyramid_level_tensor = pyramid_level_tensor.view(input_x.size(0), -1)\n",
        "            if self.pool_type == 'max_avg_pool':\n",
        "                pyramid_level_tensor_max = F.adaptive_max_pool2d(input_x, tsize)\n",
        "                pyramid_level_tensor_max = pyramid_level_tensor_max.view(input_x.size(0), -1)\n",
        "                pyramid_level_tensor_avg = F.adaptive_avg_pool2d(input_x, tsize)\n",
        "                pyramid_level_tensor_avg = pyramid_level_tensor_avg.view(input_x.size(0), -1)\n",
        "                pyramid_level_tensor = torch.cat([pyramid_level_tensor_max, pyramid_level_tensor_avg], dim=1)\n",
        "\n",
        "            pyramid_level_tensors.append(pyramid_level_tensor)\n",
        "\n",
        "        return torch.cat(pyramid_level_tensors, dim=1)\n",
        "\n",
        "     # Define the spatial pyramid pooling function\n",
        "    def _spatial_pyramid_pooling(self, input_x, levels):\n",
        "        output_sizes = [(int(2 ** level), int(2 ** level)) for level in range(levels)]\n",
        "        return self._pyramid_pooling(input_x, output_sizes)\n",
        "\n",
        "\n",
        "# Define the PHOCNet model from the GH Repo\n",
        "class PHOCNet(nn.Module):\n",
        "    def __init__(self, n_out, input_channels=3, pooling_levels=3, pool_type='max_pool'):\n",
        "        super(PHOCNet, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv_block4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pooling_layer_fn = SPP(levels=pooling_levels, pool_type=pool_type)\n",
        "        pooling_output_size = self.pooling_layer_fn.pooling_output_size\n",
        "\n",
        "        self.fc1 = nn.Linear(pooling_output_size, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, n_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_block1(x)\n",
        "        out = F.max_pool2d(out, kernel_size=2, stride=2, padding=0)\n",
        "        out = self.conv_block2(out)\n",
        "        out = F.max_pool2d(out, kernel_size=2, stride=2, padding=0)\n",
        "        out = self.conv_block3(out)\n",
        "        out = self.conv_block4(out)\n",
        "\n",
        "        out = self.pooling_layer_fn(out)\n",
        "        out = self.fc1(out)\n",
        "        out = F.relu(out)\n",
        "        out = F.dropout(out, p=0.5, training=self.training)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = F.dropout(out, p=0.5, training=self.training)\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    # Initialize weights with normal distribution\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_normal_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "QX4LlgLamvNL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test Loop"
      ],
      "metadata": {
        "id": "gSJXWrCIjkAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, test_loader, criterion, optimizer, scheduler, config, device=\"cuda\"):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10) # Watch the model with wandb\n",
        "\n",
        "    # Initialize counters\n",
        "    example_ct = 0\n",
        "    batch_ct = 0\n",
        "    model_phoc = load_model() # Load the KNN Model\n",
        "\n",
        "    # Iterate through epochs\n",
        "    for epoch in tqdm(range(int(config['epochs']))):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        # Iterate through batches of training data and train on said batch\n",
        "        for _, (images, phoc_labels, _) in enumerate(train_loader):\n",
        "            loss = train_batch(images, phoc_labels, model, optimizer, criterion, device)\n",
        "            train_loss += loss.item()\n",
        "            example_ct += len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            # Log training progress every 25 batches\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss.item(), example_ct)\n",
        "\n",
        "        loss_test = test(model, test_loader, train_loader, epoch, criterion, model_phoc, device)\n",
        "\n",
        "        # Adjust the learning rate based on the test loss\n",
        "        scheduler.step(loss_test)\n",
        "        print(scheduler._last_lr)\n",
        "        os.makedirs(config['save_model'], exist_ok=True)\n",
        "        torch.save(model.state_dict(), os.path.join(config['save_model'], f\"PHOCNET{epoch}.pt\"))\n",
        "    return model\n",
        "\n",
        "# Train on a single batch\n",
        "def train_batch(images, labels, model, optimizer, criterion, device=\"cuda\"):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs.float(), labels.float())\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Load the KNN model from a file\n",
        "def load_model():\n",
        "    return pickle.load(open(store_knn_classifier, 'rb'))\n",
        "\n",
        "\n",
        "# Predict labels using the PHOC model\n",
        "def predict_with_PHOC(phocs, model):\n",
        "    result = model.predict(phocs)\n",
        "    return result\n",
        "\n",
        "def test(model, test_loader, train_loader, epoch, criterion, model_phoc, device=\"cuda\", save=True):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      # Initialize metrics\n",
        "        loss_test = 0\n",
        "        loss_train = 0\n",
        "        correct_test = 0\n",
        "        correct_train = 0\n",
        "        edit_test = 0\n",
        "        edit_train = 0\n",
        "        test_count = 0\n",
        "        train_count = 0\n",
        "\n",
        "        # Evaluate on test data\n",
        "        for i, (images, phoc_labels, text_labels) in enumerate(test_loader):\n",
        "            images, phoc_labels = images.to(device), phoc_labels.to(device)\n",
        "            test_count += len(images)\n",
        "            outputs = model(images)\n",
        "            loss_test += criterion(outputs, phoc_labels.float())\n",
        "            predicted_labels = predict_with_PHOC(torch.sigmoid(outputs).cpu().numpy(), model_phoc)\n",
        "            correct_test += (predicted_labels == text_labels).sum().item()\n",
        "            edit_test += sum([editdistance.eval(p, t) for p, t in zip(predicted_labels, text_labels)])\n",
        "            if i == 0:\n",
        "                log_images(images, predicted_labels, text_labels[:5], epoch, \"Test\")\n",
        "\n",
        "        # Evaluate on a subset of training data\n",
        "        for i, (images, phoc_labels, text_labels) in enumerate(train_loader):\n",
        "            images, phoc_labels = images.to(device), phoc_labels.to(device)\n",
        "            train_count += len(images)\n",
        "            outputs = model(images)\n",
        "            loss_train += criterion(outputs, phoc_labels.float())\n",
        "            predicted_labels = predict_with_PHOC(torch.sigmoid(outputs).cpu().numpy(), model_phoc)\n",
        "            correct_train += (predicted_labels == text_labels).sum().item()\n",
        "            edit_train += sum([editdistance.eval(p, t) for p, t in zip(predicted_labels, text_labels)])\n",
        "            if i == 0:\n",
        "                log_images(images, predicted_labels, text_labels[:5], epoch, \"Train\")\n",
        "            if i == 150:\n",
        "                break\n",
        "\n",
        "        # Calculate average loss and accuracy\n",
        "        loss_test = loss_test / len(test_loader)\n",
        "        loss_train = loss_train / (i + 1)\n",
        "        accuracy_test = correct_test / test_count\n",
        "        accuracy_train = correct_train / train_count\n",
        "        edit_test = edit_test / test_count\n",
        "        edit_train = edit_train / train_count\n",
        "\n",
        "        train_test_log(loss_test, loss_train, accuracy_test, accuracy_train, edit_test, edit_train, epoch) # Log training and testing metrics\n",
        "\n",
        "    return loss_test"
      ],
      "metadata": {
        "id": "SDpE2erqH8x1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Pipeline"
      ],
      "metadata": {
        "id": "1YYUi7hanARX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and initialize the model, and create data loaders\n",
        "def make(config, device=\"cuda\"):\n",
        "    # Create data loaders\n",
        "    dataset = CustomDataset(config['train_dir'], transform=transform)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    # Make the model\n",
        "    model = PHOCNet(n_out=604, input_channels=3).to(device)\n",
        "    model.apply(init_weights_model)\n",
        "\n",
        "    # Define the loss criterion\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "    # Define the optimizer and learning rate scheduler\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
        "    scheduler = StepLR(optimizer, step_size=2, gamma=0.3)\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer, scheduler\n",
        "\n",
        "# Initialize weights for the model layers\n",
        "def init_weights_model(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Set parameters to require gradient computation for fine-tuning\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "# Function to run the config and training of the model\n",
        "def model_pipeline(cfg: dict) -> None:\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(project=\"phocnet-project\", config=cfg):\n",
        "        config = wandb.config\n",
        "\n",
        "        model, train_loader, test_loader, criterion, optimizer, scheduler = make(config, device)\n",
        "        model = train(model, train_loader, test_loader, criterion, optimizer, scheduler, config, device)\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "0opx6gzzm9dJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "ltriQdEqnM7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    wandb.login()\n",
        "\n",
        "    config = dict(\n",
        "        train_dir='/content/updated_train_data500images_corrected.csv',\n",
        "        test_dir='/content/updated_train_data500images_corrected.csv',\n",
        "        epochs=8,\n",
        "        batch_size=8,\n",
        "        learning_rate=0.01,\n",
        "        save_model='./models'\n",
        "    )\n",
        "\n",
        "    model = model_pipeline(config)"
      ],
      "metadata": {
        "id": "ef1PRlCinIKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8507dfc2ddde4135b7a645fbf196df8b",
            "b582421d97a44d37b32714f3b19ffe27",
            "bd3eb52e3bcb438aa5a0b414e407cd95",
            "bf4c1d8a84684e009c6796d64990e574",
            "a2cf2ebd345141f4ac5532f14a02c403",
            "4018dbe74bf04c96a8f966fec394511c",
            "d2b43fd0e2124695954c0367f5dab881",
            "9452c27516f4448f9ea43403b2e2a125"
          ]
        },
        "outputId": "5805ec81-2f5c-4a86-99ba-13f2e8cf6ed8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240529_091813-ykprsopt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marino-com/phocnet-project/runs/ykprsopt' target=\"_blank\">unique-pond-30</a></strong> to <a href='https://wandb.ai/marino-com/phocnet-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marino-com/phocnet-project' target=\"_blank\">https://wandb.ai/marino-com/phocnet-project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marino-com/phocnet-project/runs/ykprsopt' target=\"_blank\">https://wandb.ai/marino-com/phocnet-project/runs/ykprsopt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00192 examples: 0.414\n",
            "Train Loss: 0.238\n",
            "Test Loss: 0.241\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 12%|        | 1/8 [00:59<06:58, 59.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00388 examples: 0.253\n",
            "Loss after 00588 examples: 0.253\n",
            "Train Loss: 0.207\n",
            "Test Loss: 0.210\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 25%|       | 2/8 [01:46<05:10, 51.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00784 examples: 0.224\n",
            "Train Loss: 0.186\n",
            "Test Loss: 0.191\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 38%|      | 3/8 [02:38<04:21, 52.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00980 examples: 0.210\n",
            "Loss after 01180 examples: 0.207\n",
            "Train Loss: 0.182\n",
            "Test Loss: 0.186\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 50%|     | 4/8 [03:25<03:19, 49.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 01376 examples: 0.209\n",
            "Train Loss: 0.180\n",
            "Test Loss: 0.184\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 62%|   | 5/8 [04:12<02:26, 48.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 01572 examples: 0.241\n",
            "Loss after 01772 examples: 0.216\n",
            "Train Loss: 0.179\n",
            "Test Loss: 0.183\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 75%|  | 6/8 [04:57<01:35, 47.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 01968 examples: 0.192\n",
            "Train Loss: 0.183\n",
            "Test Loss: 0.188\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 88%| | 7/8 [05:42<00:46, 46.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 02164 examples: 0.194\n",
            "Loss after 02364 examples: 0.184\n",
            "Train Loss: 0.181\n",
            "Test Loss: 0.184\n",
            "[tensor(0.0100, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "100%|| 8/8 [06:29<00:00, 48.70s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.893 MB of 1.893 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8507dfc2ddde4135b7a645fbf196df8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td></td></tr><tr><td>Test accuracy</td><td></td></tr><tr><td>Test edit</td><td></td></tr><tr><td>Test loss</td><td></td></tr><tr><td>Train accuracy</td><td></td></tr><tr><td>Train edit</td><td></td></tr><tr><td>Train loss</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>7</td></tr><tr><td>Test accuracy</td><td>0.0</td></tr><tr><td>Test edit</td><td>7.64103</td></tr><tr><td>Test loss</td><td>0.1843</td></tr><tr><td>Train accuracy</td><td>0.0</td></tr><tr><td>Train edit</td><td>7.35065</td></tr><tr><td>Train loss</td><td>0.18085</td></tr><tr><td>loss</td><td>0.18431</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">unique-pond-30</strong> at: <a href='https://wandb.ai/marino-com/phocnet-project/runs/ykprsopt' target=\"_blank\">https://wandb.ai/marino-com/phocnet-project/runs/ykprsopt</a><br/> View project at: <a href='https://wandb.ai/marino-com/phocnet-project' target=\"_blank\">https://wandb.ai/marino-com/phocnet-project</a><br/>Synced 5 W&B file(s), 80 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240529_091813-ykprsopt/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8507dfc2ddde4135b7a645fbf196df8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b582421d97a44d37b32714f3b19ffe27",
              "IPY_MODEL_bd3eb52e3bcb438aa5a0b414e407cd95"
            ],
            "layout": "IPY_MODEL_bf4c1d8a84684e009c6796d64990e574"
          }
        },
        "b582421d97a44d37b32714f3b19ffe27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2cf2ebd345141f4ac5532f14a02c403",
            "placeholder": "",
            "style": "IPY_MODEL_4018dbe74bf04c96a8f966fec394511c",
            "value": "2.034 MB of 2.034 MB uploaded\r"
          }
        },
        "bd3eb52e3bcb438aa5a0b414e407cd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b43fd0e2124695954c0367f5dab881",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9452c27516f4448f9ea43403b2e2a125",
            "value": 1
          }
        },
        "bf4c1d8a84684e009c6796d64990e574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2cf2ebd345141f4ac5532f14a02c403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4018dbe74bf04c96a8f966fec394511c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2b43fd0e2124695954c0367f5dab881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9452c27516f4448f9ea43403b2e2a125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}