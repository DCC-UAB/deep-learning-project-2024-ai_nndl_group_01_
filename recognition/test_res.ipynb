{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "# Load the CSVs\n",
    "train_data = pd.read_csv(\"train_data2.csv\")\n",
    "test_data = pd.read_csv(\"test_data2.csv\")\n",
    "val_data = pd.read_csv(\"val_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "        self.voc = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "        self.num_classes = len(self.voc) + 1  # +1 para el carácter en blanco de CTC\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx, 0]\n",
    "        try:\n",
    "            image = Image.open(img_name).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {img_name}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))  # Intentar con la siguiente imagen\n",
    "        \n",
    "        text = self.data_frame.iloc[idx, 1].lower()\n",
    "        label = self.text_to_label(text)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, len(label)\n",
    "\n",
    "    def text_to_label(self, text):\n",
    "        return [self.voc.find(char) for char in text]\n",
    "\n",
    "# Definir transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 128)),  # Cambiar tamaño de la imagen\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convertir a escala de grises\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar con media y desviación estándar 0.5\n",
    "])\n",
    "\n",
    "\n",
    "# Crear dataset y dataloader\n",
    "train_dataset = CustomDataset(train_data, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, collate_fn=lambda x: x)\n",
    "\n",
    "val_dataset = CustomDataset(val_data, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=True, collate_fn=lambda x: x)\n",
    "\n",
    "test_dataset = CustomDataset(test_data, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True, collate_fn=lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    images, labels, label_lengths = zip(*batch)\n",
    "\n",
    "    images = torch.stack(images, 0)\n",
    "    labels = [torch.tensor(label) for label in labels]\n",
    "    label_lengths = torch.tensor(label_lengths)\n",
    "\n",
    "    return images, labels, label_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Entrada: [batch_size, 1, 32, 128]\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Salida: [batch_size, 32, 32, 128]\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d(2, 2),  # Salida: [batch_size, 32, 16, 64]\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Salida: [batch_size, 64, 16, 64]\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d(2, 2),  # Salida: [batch_size, 64, 8, 32]\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Salida: [batch_size, 128, 8, 32]\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d((2, 1)),  # Salida: [batch_size, 128, 4, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # Salida: [batch_size, 256, 4, 32]\n",
    "            nn.SELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d((2, 1)),  # Salida: [batch_size, 256, 2, 32]\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),  # Salida: [batch_size, 512, 2, 32]\n",
    "            nn.SELU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d((2, 1)),  # Salida: [batch_size, 512, 1, 32]\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.LSTM(512, 128, bidirectional=True, batch_first=True, num_layers=2)  # Entrada: [batch_size, 31, 512], Salida: [batch_size, 31, 256]\n",
    "        self.fc = nn.Linear(256, num_classes)  # Entrada: [batch_size, 31, 256], Salida: [batch_size, 31, num_classes]\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, nonlinearity='selu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, nonlinearity='selu')\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        init.kaiming_normal_(param, nonlinearity='selu')\n",
    "                    elif 'bias' in name:\n",
    "                        init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x inicial: [batch_size, 1, 32, 128]\n",
    "        x = self.cnn(x)\n",
    "        # Salida: [batch_size, 512, 1, 31]\n",
    "        x = x.squeeze(2)  # Remover la dimensión 2 que es 1, resultado: [batch_size, 512, 31]\n",
    "        x = x.permute(0, 2, 1)  # Reorganizar a [batch_size, 31, 512]\n",
    "        \n",
    "        x, _ = self.rnn(x)\n",
    "        # Salida esperada: [batch_size, 31, 256]\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        # Salida esperada: [batch_size, 31, num_classes]\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def ctc_decode(log_probs, voc, blank_index=0):\n",
    "    \"\"\"\n",
    "    Decodificar las probabilidades de salida de la RNN para obtener la secuencia de texto.\n",
    "\n",
    "    log_probs: Salida logarítmica del modelo RNN después de aplicar softmax (T, N, C)\n",
    "    voc: El vocabulario usado para el mapeo de caracteres\n",
    "    blank_index: Índice usado para el carácter en blanco en CTC\n",
    "    \"\"\"\n",
    "    # Obtener los índices con la mayor probabilidad en cada timestep\n",
    "    max_probs = torch.argmax(log_probs, dim=-1)\n",
    "    \n",
    "    decoded_batch = []\n",
    "    for sequence in max_probs.permute(1, 0):  # Cambiar a (N, T)\n",
    "        decoded_sequence = []\n",
    "        previous_char = None\n",
    "        for index in sequence:\n",
    "            if index != blank_index:  # Ignorar el carácter en blanco\n",
    "                char = voc[index] if index < len(voc) else ''\n",
    "                if char != previous_char:  # Eliminar duplicados consecutivos\n",
    "                    decoded_sequence.append(char)\n",
    "                previous_char = char\n",
    "        decoded_sequence = ''.join(decoded_sequence)  # Unir los caracteres\n",
    "        decoded_batch.append(decoded_sequence)\n",
    "    return decoded_batch\n",
    "\n",
    "# Asegúrate de que la configuración del vocabulario sea correcta\n",
    "train_dataset.voc = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "# Definir el número de clases incluyendo el índice en blanco\n",
    "num_classes = len(train_dataset.voc) + 1\n",
    "model = CRNN(num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"model_epoch_24.pth\"))\n",
    "\n",
    "model.eval()\n",
    "pred_total = []\n",
    "true_total = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, label_lengths in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = [label.to(device) for label in labels]\n",
    "        label_lengths = label_lengths.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        \n",
    "        \n",
    "        log_probs = F.log_softmax(logits, dim=2).permute(1, 0, 2)\n",
    "        input_lengths = torch.full((logits.size(0),), logits.size(1), dtype=torch.long).to(device)\n",
    "        labels_concat = torch.cat(labels).to(device)\n",
    "        \n",
    "        pred_texts = ctc_decode(log_probs, train_dataset.voc)\n",
    "        true_texts = [\"\".join([train_dataset.voc[char] for char in label]) for label in labels]\n",
    "        pred_total.extend(pred_texts)\n",
    "        true_total.extend(true_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Word Accuracy: 0.54\n",
      "Validation Character Accuracy: 0.76\n",
      "Validation Average Levenshtein Distance: 0.94\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein as lev\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Calcular accuracy por palabras\n",
    "word_acc = accuracy_score(true_total, pred_total)\n",
    "\n",
    "# Calcular accuracy por caracteres\n",
    "correct_chars = sum([1 for gt_word, pred_word in zip(true_total, pred_total) for gt_char, pred_char in zip(gt_word, pred_word) if gt_char == pred_char])\n",
    "total_chars = sum([len(gt_word) for gt_word in true_total])\n",
    "char_acc = correct_chars / total_chars\n",
    "\n",
    "# Calcular distancia de Levenshtein promedio\n",
    "lev_distances = [lev.distance(gt_word, pred_word) for gt_word, pred_word in zip(true_total, pred_total)]\n",
    "avg_lev_distance = sum(lev_distances) / len(lev_distances)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f'Validation Word Accuracy: {word_acc:.2f}')\n",
    "print(f'Validation Character Accuracy: {char_acc:.2f}')\n",
    "print(f'Validation Average Levenshtein Distance: {avg_lev_distance:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Metrics\n",
    "\n",
    "* Word Accuracy\n",
    "\n",
    "This metric represents the proportion of predicted words that exactly match the ground truth words. A higher value indicates that more words are predicted correctly.\n",
    "\n",
    "* Character Accuracy\n",
    "\n",
    "This metric measures the percentage of characters in the predicted words that match the characters in the ground truth words. It shows how accurate the model is at the character level, even if the entire word is not correct.\n",
    "\n",
    "* Average Levenshtein Distance\n",
    "\n",
    "This metric indicates the average number of edits (insertions, deletions, or substitutions) needed to transform a predicted word into the corresponding ground truth word. A lower value means the predicted words are more similar to the ground truth words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Asegúrate de que la configuración del vocabulario sea correcta\n",
    "train_dataset.voc = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "# Definir el número de clases incluyendo el índice en blanco\n",
    "\n",
    "model.eval()\n",
    "pred_total = []\n",
    "true_total = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, label_lengths in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = [label.to(device) for label in labels]\n",
    "        label_lengths = label_lengths.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        \n",
    "        \n",
    "        log_probs = F.log_softmax(logits, dim=2).permute(1, 0, 2)\n",
    "        input_lengths = torch.full((logits.size(0),), logits.size(1), dtype=torch.long).to(device)\n",
    "        labels_concat = torch.cat(labels).to(device)\n",
    "        \n",
    "        pred_texts = ctc_decode(log_probs, train_dataset.voc)\n",
    "        true_texts = [\"\".join([train_dataset.voc[char] for char in label]) for label in labels]\n",
    "        pred_total.extend(pred_texts)\n",
    "        true_total.extend(true_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Word Accuracy: 0.54\n",
      "Test Character Accuracy: 0.76\n",
      "Test Average Levenshtein Distance: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Calcular accuracy por palabras\n",
    "word_acc = accuracy_score(true_total, pred_total)\n",
    "\n",
    "# Calcular accuracy por caracteres\n",
    "correct_chars = sum([1 for gt_word, pred_word in zip(true_total, pred_total) for gt_char, pred_char in zip(gt_word, pred_word) if gt_char == pred_char])\n",
    "total_chars = sum([len(gt_word) for gt_word in true_total])\n",
    "char_acc = correct_chars / total_chars\n",
    "\n",
    "# Calcular distancia de Levenshtein promedio\n",
    "lev_distances = [lev.distance(gt_word, pred_word) for gt_word, pred_word in zip(true_total, pred_total)]\n",
    "avg_lev_distance = sum(lev_distances) / len(lev_distances)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f'Test Word Accuracy: {word_acc:.2f}')\n",
    "print(f'Test Character Accuracy: {char_acc:.2f}')\n",
    "print(f'Test Average Levenshtein Distance: {avg_lev_distance:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_and_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
